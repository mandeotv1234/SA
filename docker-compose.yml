services:
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    environment:
      CLUSTER_ID: "N9U05a1yRjKiav1x1Z2T4Q"
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_LOG_RETENTION_BYTES: 268435456
      KAFKA_LOG_SEGMENT_BYTES: 134217728
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    ports:
      - "9092:9092"
    healthcheck:
      test: nc -z localhost 9092 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
      POSTGRES_DB: appdb
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U dev -d appdb" ]
      interval: 5s
      timeout: 5s
      retries: 5

  timescaledb:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
      POSTGRES_DB: timeseriesdb
    ports:
      - "5433:5432"
    volumes:
      - tsdata:/var/lib/postgresql/data

  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  haproxy:
    image: haproxy:2.8
    container_name: haproxy
    ports:
      - "8005:8005"
      - "8404:8404"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      stream-service:
        condition: service_healthy
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kong:
    image: kong/kong-gateway:3.6
    container_name: kong
    ports:
      - "8000:8000" # ONLY Kong Gateway exposes ports externally
      - "8001:8001" # Kong Admin API (for configuration)
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: "/kong/kong.yml"
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_HEADERS: "off"
    volumes:
      - ./infra/kong_conf/kong.yml:/kong/kong.yml:ro
    depends_on:
      kong-init:
        condition: service_completed_successfully
      haproxy:
        condition: service_started
    networks:
      - internal
      - default

  kong-init:
    image: python:3.11-slim
    command: >
      sh -c "pip install requests pyyaml && python /app/infra/generate_kong_yml.py"
    volumes:
      - .:/app:rw
    depends_on:
      auth-service:
        condition: service_started
    networks:
      - default

  auth-service:
    build:
      context: ./services/auth-service
    env_file:
      - ./services/auth-service/.env # Business logic configs (JWT, etc.)
    environment:
      # Infrastructure configs (DB, Kafka, Redis)
      DATABASE_URL: postgresql://dev:dev@postgres:5432/appdb
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
      REDIS_HOST: redis
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "8081:8080"
    volumes:
      - ./services/auth-service:/app
      - /app/node_modules
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/auth/public-key || exit 1" ]
      interval: 5s
      timeout: 3s
      retries: 12
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  core-service:
    build:
      context: ./services/core-service
    environment:
      DATABASE_URL: postgresql://dev:dev@timescaledb:5432/timeseriesdb
      KAFKA_BROKERS: kafka:9092
      MARKET_DATA_TOPIC: market.prices
      AI_INSIGHTS_TOPIC: ai_insights
      MARKET_CONSUMER_GROUP_ID: core-service-market-consumer
      NEWS_CONSUMER_GROUP_ID: core-service-news-consumer
      REDIS_URL: redis://redis:6379 # For token blacklist defense-in-depth
    depends_on:
      timescaledb:
        condition: service_started
      redis:
        condition: service_started
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "3001:3000"
    volumes:
      - ./services/core-service:/app
      - /app/node_modules
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 6
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  stream-service:
    build:
      context: ./services/stream-service
    environment:
      KAFKA_BROKERS: kafka:9092
      REDIS_URL: redis://redis:6379
      SYMBOLS: "btcusdt,ethusdt,bnbusdt,solusdt,dogeusdt,adausdt,xrpusdt,avaxusdt,dotusdt,polusdt"
      SEND_PARTIAL: "true"
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "3002-3005:3000"
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./services/stream-service:/app
      - /app/node_modules
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/health || exit 1" ]
      interval: 3s # Faster detection for consistent hashing
      timeout: 2s # Reduced timeout
      retries: 3 # Fail fast to trigger rehashing
      start_period: 30s
    deploy:
      replicas: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  crawler-service:
    build:
      context: ./services/crawler-service
    environment:
      KAFKA_BROKERS: kafka:9092
      REDIS_URL: redis://redis:6379/0
      CRAWL_INTERVAL_SECONDS: "60"
      LOG_LEVEL: "DEBUG"
      NEWS_RAW_TOPIC: news_raw
      OLLAMA_API_URL: ${OLLAMA_API_URL}
      MONGO_URL: "mongodb://mongo-crawler:27017"
      MONGO_DB: "crawler_db"
      GEMINI_API_KEY: "${GEMINI_API_KEY}"
      CRAWL_SOURCES: >-
        https://cointelegraph.com/rss, https://cryptonews.com/news/feed/, https://decrypt.co/feed, https://bitcoinmagazine.com/.rss/full/, https://theblock.co/rss.xml, https://www.coindesk.com/arc/outboundfeeds/rss/, https://coin68.com/, https://blogtienao.com/, https://coinphoton.com/, https://tienthuattoan.com/, https://cryptoslate.com/feed/, https://u.today/rss, https://ambcrypto.com/feed/, https://cryptopotato.com/feed/, https://beincrypto.com/feed/, https://cryptobriefing.com/feed/, https://coinjournal.net/feed/, https://www.newsbtc.com/feed/
    depends_on:
      redis:
        condition: service_started
      mongo-crawler:
        condition: service_started
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "8003:8001"
    volumes:
      - ./services/crawler-service:/app
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8001/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 6
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  mongo-crawler:
    image: mongo:6.0
    container_name: mongo-crawler
    ports:
      - "27018:27017"
    volumes:
      - mongo_crawler_data:/data/db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ai-service:
    build:
      context: ./services/ai-service
    environment:
      KAFKA_BROKERS: kafka:9092
      NEWS_RAW_TOPIC: news_raw
      NEWS_ANALYZED_TOPIC: news_analyzed
      KAFKA_GROUP: ai-service-group-latest-only-v1
      AI_INSIGHTS_TOPIC: ai_insights
      MARKET_DATA_TOPIC: market.prices

      # Deep Learning Config
      MODEL_PATH: "/app/models/lstm_sentiment_hybrid_v1.pth"
      DEVICE: "cpu" # Docker on macOS cannot access GPU directly yet. Use 'cpu'.
      TIMEFRAME: "5m"

      # Ollama configuration
      OLLAMA_API_URL: ${OLLAMA_API_URL}
      OLLAMA_MODEL: "llama3.2"

      # Settings
      PREDICTION_INTERVAL_SEC: "60"
      MAX_NEWS_BUFFER: "5000"
      DEBUG_MARKET_CACHE: "true"
    volumes:
      - ./services/ai-service:/app
      - ./ml_models:/app/models
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8002/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 6
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "8002:8002"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  stream-ingester:
    build:
      context: ./services/stream-ingester
    environment:
      KAFKA_BROKERS: kafka:9092
      SYMBOLS: "btcusdt,ethusdt,bnbusdt,solusdt,dogeusdt,adausdt,xrpusdt,avaxusdt,dotusdt,polusdt"
    depends_on:
      kafka:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  payment-service:
    build:
      context: ./services/payment-service
    environment:
      KAFKA_BROKERS: kafka:9092
      PORT: 3000
      SEPAY_API_KEY: "${SEPAY_API_KEY}"
      DATABASE_URL: postgresql://payment_user:payment_password@payment-db:5432/payment_db
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "8004:3000"
    depends_on:
      kafka:
        condition: service_healthy
      payment-db:
        condition: service_healthy
    volumes:
      - ./services/payment-service:/app
      - /app/node_modules
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 6
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  payment-db:
    image: postgres:15
    environment:
      POSTGRES_USER: payment_user
      POSTGRES_PASSWORD: payment_password
      POSTGRES_DB: payment_db
    ports:
      - "5435:5432"
    volumes:
      - payment_pgdata:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U payment_user -d payment_db" ]
      interval: 5s
      timeout: 5s
      retries: 5

  investment-service:
    build:
      context: ./services/investment-service
    container_name: investment-service
    environment:
      POSTGRES_HOST: investment-db
      POSTGRES_DB: investment_db
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
      PORT: 8001
      KAFKA_BROKERS: kafka:9092
    depends_on:
      investment-db:
        condition: service_healthy
      ai-service:
        condition: service_started
      kafka:
        condition: service_healthy
    # SECURITY: No port exposure - only accessible via Kong Gateway
    # ports:
    #   - "8006:8001"
    volumes:
      - ./services/investment-service:/app
      - /app/node_modules
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8001/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - internal
      - default

  investment-db:
    image: postgres:15-alpine
    container_name: investment-db
    environment:
      POSTGRES_DB: investment_db
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
    ports:
      - "5436:5432"
    volumes:
      - investment_pgdata:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U dev -d investment_db" ]
      interval: 5s
      timeout: 5s
      retries: 5

volumes:
  pgdata:
    driver: local
  tsdata:
    driver: local
  redisdata:
    driver: local
  payment_pgdata:
    driver: local
  mongo_crawler_data:
    driver: local
  investment_pgdata:
    driver: local

networks:
  default:
    driver: bridge
  internal:
    driver: bridge
    internal: false # SECURITY: Set to true in production to create isolated internal network
    # When internal: true, services on this network cannot reach external internet
    # Only Kong Gateway should be on both networks to act as the sole entry point
