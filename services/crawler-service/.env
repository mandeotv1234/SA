# Crawler service environment
# Redis (use 'redis' when running inside docker-compose where a redis service exists)
REDIS_URL=redis://redis:6379/0

# Comma-separated list of news site homepages to discover article links from
CRAWL_SOURCES=https://www.coindesk.com,https://vnexpress.net

# How often to run discovery (seconds). Default: 15 minutes
CRAWL_INTERVAL_SECONDS=60

# TTL for seen URL deduplication in seconds (default: 7 days)
CRAWLER_REDIS_TTL=604800

# Kafka broker(s) - use 'kafka:9092' for docker-compose or 'localhost:9092' for local
KAFKA_BROKERS=kafka:9092

# Kafka topic to publish raw news
NEWS_RAW_TOPIC=news_raw

# Gemini API key used for Google Generative Models (gemini). Keep empty to disable.
GEMINI_API_KEY=

# Kafka producer options
KAFKA_ACKS=all
# Extra producer config (comma-separated key=value pairs). Example: linger.ms=100,compression.type=snappy
KAFKA_PRODUCER_CONFIG=

# Logging
LOG_LEVEL=INFO
KAFKA_BROKERS=localhost:9092
NEWS_RAW_TOPIC=news_raw
GEMINI_API_KEY=
